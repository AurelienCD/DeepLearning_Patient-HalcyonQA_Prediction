{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb8a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pad \n",
    "import numpy as np\n",
    "from numpy.core.numeric import NaN\n",
    "\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statistics\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.multicomp as multi \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import  make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e0ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df           = pad.read_excel('DATA_IA_CQ_Halcyon.xlsx')\n",
    "list_to_drop = ['ID Patient', 'Nom du Case', 'G_2.5/2.5', 'G_3/3', 'G_2/3', 'G_2/2.5', 'G_3/2', 'ID faisceau ']\n",
    "df_drop      = df.drop(list_to_drop, axis =1)\n",
    "df_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12955047",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict_features = ['Class_2.5/2.5', 'Class_3/3', 'Class_3/2', 'Class_2/3', 'Class_2/2.5']\n",
    "\n",
    "Y = df_drop[to_predict_features]\n",
    "X = df_drop.drop(to_predict_features, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c36343e",
   "metadata": {},
   "source": [
    "#### There is not interest to keep other metrics than SAS10 BA BI as statistical anaylysis have shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc274c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_drop['Class_2/2.5']\n",
    "X = df_drop[['SAS10', 'BA', 'BI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85ed33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np   = np.array(X)\n",
    "sc     = StandardScaler()\n",
    "X_norm = sc.fit_transform(X_np)\n",
    "X      = X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e9113",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dump(sc, 'StandardScaler_SAS10_BA_BI.joblib')\n",
    "dump(X, 'X_norm_SAS10_BA_BI.joblib')\n",
    "dump(Y, 'Y_2-25.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f290fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load('X_norm_SAS10_BA_BI.joblib')\n",
    "Y = load('Y.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d120678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load('X_norm.joblib')\n",
    "Y = load('Y.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4640aab2",
   "metadata": {},
   "source": [
    "## Entrainement des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7913c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y['Class_2/2.5'], test_size = 0.20, random_state = 10)\n",
    "\n",
    "#ros = RandomOverSampler(sampling_strategy = 'minority')\n",
    "#X_train_res, y_train_res = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b3cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des modèles\n",
    "List_of_models = [LinearDiscriminantAnalysis(), RidgeClassifier(), KNeighborsClassifier(), GaussianNB(), DecisionTreeClassifier(), SVC(), SGDClassifier(), RandomForestClassifier()]\n",
    "List_of_models_for_graph = [\"LinearDiscriminant\", \"Ridge\", \"KNeighbors\", \"GaussianNB\", \"DecisionTree\", \"SVC\", \"SGD\", \"RandomForestClassifier\"]\n",
    "\n",
    "def run_model_and_performance_check(model):\n",
    "\n",
    "    # Choix du modèle et entraînement du modèle\n",
    "    model_class = model\n",
    "    model_class.fit(X_train, y_train)\n",
    "\n",
    "    # Prédiction du modèle et archivage des résultats\n",
    "    y_pred = model_class.predict(X_test)\n",
    "\n",
    "    # Création des dataframes résultats\n",
    "    results_classification = np.array([model_class.score(X_train,y_train), model_class.score(X_test,y_test)])\n",
    "    df_results = pad.DataFrame(index = [\"Score entrainement\", \"Score de prédiction\"], columns = [str(model)[:-2]])\n",
    "    df_results[str(model)[:-2]] = results_classification\n",
    "\n",
    "    return df_results\n",
    "\n",
    "df_results = pad.DataFrame(index = [\"Score entrainement\", \"Score de prédiction\", \"MAE\", \"RMSE\", \"median absolute error\"], columns = [\"LinearDiscriminant\"])\n",
    "\n",
    "for i in range(len(List_of_models)):\n",
    "  model_class = List_of_models[i] \n",
    "  model_class.fit(X_train, y_train)\n",
    "  y_pred = model_class.predict(X_test)\n",
    "  results_classification = np.array([model_class.score(X_train,y_train), model_class.score(X_test,y_test), mean_absolute_error(y_test,y_pred), np.sqrt(mean_squared_error(y_test,y_pred)), median_absolute_error(y_test,y_pred)])\n",
    "  df_results[List_of_models_for_graph[i]] = results_classification\n",
    "\n",
    "custom_palette = [sns.xkcd_rgb[\"windows blue\"], sns.xkcd_rgb[\"pale red\"], sns.xkcd_rgb[\"medium green\"], \"orange\", \"blue\",\"yellow\", \"purple\", \"deeppink\", \"brown\", \"teal\", \"black\"] \n",
    "sns.set_palette(custom_palette)\n",
    "\n",
    "df_graph = df_results.transpose()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax1 = sns.barplot(x=df_graph.index, y=df_graph[\"Score entrainement\"].values, data=df_graph, ax=axs[0], palette = custom_palette)\n",
    "ax2 = sns.barplot(x=df_graph.index, y=df_graph[\"Score de prédiction\"].values, data=df_graph, ax=axs[1], palette = custom_palette)\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(),rotation=50)\n",
    "ax1.set_title('Efficacité des modèles pour la prédiction du G_2.5/2.5')\n",
    "ax1.set_ylabel('Score entrainement')\n",
    "ax1.set(ylim=(0, 1))\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(),rotation=50)\n",
    "ax2.set_title('Efficacité des modèles pour la prédiction du G_2.5/2.5')\n",
    "ax2.set_ylabel('Score de prédiction')\n",
    "ax2.set(ylim=(0, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "#fig.savefig(\"Performance modèles classification all data\", dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c206319b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modèle LinearDiscriminant \n",
    "LinearDiscriminant_parameters = {'solver' : ['svd', 'lsqr', 'eigen'], \n",
    "                                 'store_covariance' : [True, False],\n",
    "                                 'tol' : [0.0001,0.0002,0.0003]}\n",
    "\n",
    "LinearDiscriminant_GridSearchCV = GridSearchCV(estimator = LinearDiscriminantAnalysis(), param_grid = LinearDiscriminant_parameters, cv = 5, n_jobs=-1)\n",
    "LinearDiscriminant_GridSearchCV.fit(X_train, y_train)\n",
    "LinearDiscriminant_GridSearchCV.best_params_\n",
    "print(\"LinearDiscriminant best param = \" + str(LinearDiscriminant_GridSearchCV.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566d2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle RidgeClassifier\n",
    "RidgeClassifier_parameters = {'alpha' : list(range(1,20)),\n",
    "                              'fit_intercept' : [True, False],\n",
    "                              'copy_X' : [True, False],\n",
    "                              'tol' : [0.0001,0.0002,0.0003],\n",
    "                              'solver' : ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}\n",
    "\n",
    "RidgeClassifier_GridSearchCV = GridSearchCV(estimator = RidgeClassifier(), param_grid = RidgeClassifier_parameters, cv = 5, n_jobs=-1)\n",
    "RidgeClassifier_GridSearchCV.fit(X_train, y_train)\n",
    "RidgeClassifier_GridSearchCV.best_params_\n",
    "print(\"RidgeClassifier best param = \" + str(RidgeClassifier_GridSearchCV.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f234a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle KNeighbors\n",
    "KNeighborsClassifier_parameters = {#'n_neighbors' : list(range(1,50)),\n",
    "                                   #'leaf_size' : list(range(1,30)), \n",
    "                                   'p':[1,2], \n",
    "                                   'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
    "                                   'metric' : ['minkowski','euclidean','manhattan']}\n",
    "\n",
    "KNeighborsClassifier_GridSearchCV = GridSearchCV(estimator = KNeighborsClassifier(), param_grid = KNeighborsClassifier_parameters, cv = 5, n_jobs=-1)\n",
    "KNeighborsClassifier_GridSearchCV.fit(X_train, y_train)\n",
    "KNeighborsClassifier_GridSearchCV.best_params_\n",
    "print(\"KNeighborsClassifier best param = \" + str(KNeighborsClassifier_GridSearchCV.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb3d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle GaussianNB\n",
    "GaussianNB_parameters = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "GaussianNB_GridSearchCV = GridSearchCV(estimator = GaussianNB(), param_grid = GaussianNB_parameters, cv = 5, n_jobs=-1)\n",
    "GaussianNB_GridSearchCV.fit(X_train, y_train)\n",
    "GaussianNB_GridSearchCV.best_params_\n",
    "\n",
    "print(\"GaussianNB best param = \" +str(GaussianNB_GridSearchCV.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b41eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle DecisionTree\n",
    "DecisionTreeClassifier_parameters = {#'max_features' : ['auto', 'sqrt', '“log2'],\n",
    "                                     'max_depth': [2, 10, 15,18,20],\n",
    "                                     'min_samples_leaf': [1, 2, 5, 10, 20, 50, 100],\n",
    "                                     \"min_samples_split\": [2, 6, 20],\n",
    "                                     'criterion': [\"gini\", \"entropy\"],\n",
    "                                     'splitter' : ['best', 'random'],\n",
    "                                     'min_samples_split' : np.linspace(0.1, 1.0, 5, endpoint=True).tolist()}\n",
    "\n",
    "DecisionTreeClassifier_GridSearchCV = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid = DecisionTreeClassifier_parameters, cv = 5, n_jobs=-1, verbose = 2)\n",
    "DecisionTreeClassifier_GridSearchCV.fit(X_train, y_train)\n",
    "DecisionTreeClassifier_GridSearchCV.best_params_\n",
    "print(\"DecisionTreeClassifier best param = \" +str(DecisionTreeClassifier_GridSearchCV.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa7ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle SVC\n",
    "SVC_parameters = {#'C': [1, 10, 50, 100, 200, 300],\n",
    "                  'gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "                  'kernel': ['rbf', 'linear', 'poly', 'sigmoid'],\n",
    "                  'probability': [True, False]}\n",
    "                  \n",
    "SVC_GridSearchCV = GridSearchCV(estimator = SVC(), param_grid = SVC_parameters, cv=5, n_jobs=-1, verbose=2)\n",
    "SVC_GridSearchCV.fit(X_train, y_train)\n",
    "SVC_GridSearchCV.best_params_\n",
    "print(\"SVC best param = \" +str(SVC_GridSearchCV.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee9cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modèle SGD\n",
    "SGD_parameters = {'loss' : ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "                  'penalty' : ['l1', 'l2', 'elasticnet'], \n",
    "                  'alpha' : [1e-5, 1e-4, 1e-3, 1e-2, 1e-1], \n",
    "                  'l1_ratio' : [0, 0.10, 0.15, 0.20, 0.30], \n",
    "                  'fit_intercept' : [True, False],\n",
    "                  'tol' : [0.0001,0.0002,0.0003]}\n",
    "\n",
    "\n",
    "SGD_GridSearchCV = GridSearchCV(estimator = SGDClassifier(), param_grid = SGD_parameters, cv=5, n_jobs=-1, verbose=2)\n",
    "SGD_GridSearchCV.fit(X_train, y_train)\n",
    "SGD_GridSearchCV.best_params_\n",
    "print(\"SGD best param = \" +str(SGD_GridSearchCV.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4470a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle RandomForestClassifier\n",
    "RandomForestClassifier_parameters = {'criterion' : ['gini', 'entropy', 'log_loss'],\n",
    "                                     'n_estimators' : [int(x) for x in np.linspace(start = 200, stop = 5000, num = 10)], \n",
    "                                     'min_samples_split' : [2,5,7,9,10, 15, 20], \n",
    "                                     'min_samples_leaf' : [1,2,5,7,8, 12, 15], \n",
    "                                     'max_features' : ['auto', 'sqrt', 'log2'], \n",
    "                                     'max_depth' : [int(x) for x in np.linspace(10,110, num = 11), None]}\n",
    "\n",
    "RandomForestClassifier_GridSearchCV = GridSearchCV(estimator = RandomForestClassifier(), param_grid = RandomForestClassifier_parameters, cv=5, n_jobs=-1, verbose=2, n_iter = 500)\n",
    "RandomForestClassifier_GridSearchCV.fit(X_train, y_train)\n",
    "RandomForestClassifier_GridSearchCV.best_params_\n",
    "coefficients = RandomForestClassifier_GridSearchCV.best_estimator_.feature_importances_\n",
    "print(\"RandomForestClassifier best param = \" +str(RandomForestClassifier_GridSearchCV.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b774a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle RandomForestClassifier\n",
    "RandomForestClassifier_parameters = {'criterion' : ['gini', 'entropy'],\n",
    "                                     'n_estimators' : [1,10,20,30, 100, 200, 400], \n",
    "                                     'min_samples_split' : [2,5,7,9,10], \n",
    "                                     'min_samples_leaf' : [1,2,5,7,9,10], \n",
    "                                     'max_features' : ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "\n",
    "RandomForestClassifier_GridSearchCV = GridSearchCV(estimator = RandomForestClassifier(), param_grid = RandomForestClassifier_parameters, cv=5, n_jobs=-1, verbose=2)\n",
    "RandomForestClassifier_GridSearchCV.fit(X_train, y_train)\n",
    "RandomForestClassifier_GridSearchCV.best_params_\n",
    "coefficients = RandomForestClassifier_GridSearchCV.best_estimator_.feature_importances_\n",
    "print(\"RandomForestClassifier best param = \" +str(RandomForestClassifier_GridSearchCV.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea6097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LinearDiscriminant_GridSearchCV.best_params_)\n",
    "\n",
    "print(RidgeClassifier_GridSearchCV.best_params_)\n",
    "\n",
    "print(KNeighborsClassifier_GridSearchCV.best_params_)\n",
    "\n",
    "print(GaussianNB_GridSearchCV.best_params_)\n",
    "\n",
    "print(DecisionTreeClassifier_GridSearchCV.best_params_)\n",
    "\n",
    "print(SVC_GridSearchCV.best_params_)\n",
    "\n",
    "print(SGD_GridSearchCV.best_params_)\n",
    "\n",
    "print(RandomForestClassifier_GridSearchCV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e6b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "List_of_models = [LinearDiscriminantAnalysis(solver = 'svd', store_covariance = True, tol = 0.0001),\n",
    "                  RidgeClassifier(alpha = 13, copy_X = True, fit_intercept = False, solver = 'auto', tol = 0.0001),\n",
    "                  KNeighborsClassifier(algorithm = 'auto', metric = 'minkowski', p = 1),\n",
    "                  GaussianNB(var_smoothing = 0.2848035868435802),\n",
    "                  DecisionTreeClassifier(criterion = 'gini', max_depth = 2, min_samples_leaf = 100, min_samples_split = 0.1, splitter = 'best'),\n",
    "                  SVC(gamma = 0.1, kernel = 'sigmoid', probability = True),\n",
    "                  SGDClassifier(alpha = 0.001, fit_intercept = False, l1_ratio = 0.2, loss = 'huber', penalty = 'l2', tol = 0.0002),\n",
    "                  RandomForestClassifier(criterion = 'entropy', max_features = 'auto', min_samples_leaf = 2, min_samples_split = 5, n_estimators = 30)]\n",
    "\n",
    "List_of_models_for_graph = [\"LinearDiscriminant\", \"Ridge\", \"KNeighbors\", \"GaussianNB\", \"DecisionTree\", \"SVC\", \"SGD\", \"RandomForestClassifier\"]\n",
    "\n",
    "df_results = pad.DataFrame(index = [\"Score entrainement\", \"Score de prédiction\", \"MAE\", \"RMSE\", \"median absolute error\"], columns = [\"LinearDiscriminant\"])\n",
    "\n",
    "custom_palette = [sns.xkcd_rgb[\"windows blue\"], sns.xkcd_rgb[\"pale red\"], sns.xkcd_rgb[\"green blue\"], \"orange\", sns.xkcd_rgb[\"blue\"],sns.xkcd_rgb[\"sunny yellow\"], sns.xkcd_rgb[\"warm purple\"], sns.xkcd_rgb[\"medium green\"], \"brown\", \"teal\", \"black\"] \n",
    "sns.set_palette(custom_palette)\n",
    "\n",
    "#custom_palette = sns.color_palette(\"tab10\")\n",
    "\n",
    "for i in range(len(List_of_models)):\n",
    "  model_class = List_of_models[i] \n",
    "  model_class.fit(X_train, y_train)\n",
    "  y_pred = model_class.predict(X_test)\n",
    "  results_classification = np.array([model_class.score(X_train,y_train), model_class.score(X_test,y_test), mean_absolute_error(y_test,y_pred), np.sqrt(mean_squared_error(y_test,y_pred)), median_absolute_error(y_test,y_pred)])\n",
    "  df_results[List_of_models_for_graph[i]] = results_classification\n",
    "\n",
    "  df_graph = df_results.transpose()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax1 = sns.barplot(x=df_graph.index, y=df_graph[\"Score entrainement\"].values, data=df_graph, ax=axs[0], palette = custom_palette)\n",
    "ax2 = sns.barplot(x=df_graph.index, y=df_graph[\"Score de prédiction\"].values, data=df_graph, ax=axs[1], palette = custom_palette)\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(),rotation=45)\n",
    "#ax1.set_title('Efficacité des modèles pour la prédiction du gamma moyen \\n pour toutes les localisations')\n",
    "ax1.set_ylabel('Training score')\n",
    "ax1.set(ylim=(0, 1))\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(),rotation=45)\n",
    "#ax2.set_title('Efficacité des modèles pour la prédiction du gamma moyen \\n pour toutes les localisations')\n",
    "ax2.set_ylabel('Validation score')\n",
    "ax2.set(ylim=(0, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"Performance modèles ML trois metriques\", dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246eb090",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a10160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFC = RandomForestClassifier(criterion = 'gini', max_depth = 80, max_features = 'auto', min_samples_leaf = 1, min_samples_split = 7, n_estimators = 200)\n",
    "\n",
    "RFC = RandomForestClassifier(criterion = 'entropy', max_features = 'auto', min_samples_leaf = 2, min_samples_split = 5, n_estimators = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3d21e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2a842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = RFC.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f6303e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = Y['Class_2/2.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a962f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(Y, pred)\n",
    "print(\"AUC = \" + str(round(auc,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf91839",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Y\n",
    "#y = y[:,1]\n",
    "yhat = RFC.predict(X)\n",
    "#yhat = yhat[:,1]\n",
    "\n",
    "from numpy import argmax\n",
    "from numpy import sqrt\n",
    "\n",
    "#yhat = model_rfc.predict_proba(X)\n",
    "# keep probabilities for the positive outcome only\n",
    "#yhat = yhat[:, 1]\n",
    "\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(y, yhat)\n",
    "# calculate the g-mean for each threshold\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix = argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "auc = roc_auc_score(y, yhat)\n",
    "print('AUC=%f' %auc)\n",
    "# plot the roc curve for the model\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "plt.plot(fpr, tpr, marker='.', label='RandomForestClassifier')\n",
    "plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "plt.text(0.5,0.8,'AUC=%f' %round(auc,4) ,horizontalalignment='center',\n",
    "     verticalalignment='center', fontsize=10, color='black')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"RFC one class\", dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa0d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "#pred = model.predict(inputs[test])\n",
    "conf_matrix_SGD_01 = tf.math.confusion_matrix(labels=Y, predictions=pred)\n",
    " \n",
    "ax_sgd_01 = sns.heatmap(conf_matrix_SGD_01, annot = True, fmt='d')\n",
    "ax_sgd_01.set_title('RandomForestClassifier, AUC = ' + str(round(auc,4)))\n",
    "ax_sgd_01.set_ylabel('Réel')\n",
    "ax_sgd_01.set_xlabel('Prédiction')\n",
    "plt.savefig(\"Matrice de confusion RFC\", dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0211ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 120\n",
    "TN = 155\n",
    "FP = 20\n",
    "FN = 23\n",
    "sensitivity = TP/(TP+FN)\n",
    "specificity = TN/(TN+FP)\n",
    "print(\"sensitivity = \" + str(sensitivity))\n",
    "print(\"specificity = \" + str(specificity))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
